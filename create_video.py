#!/usr/bin/env python3
"""
Generate a video from saved logs: displays images, text, state and actions data on white background.
Logs directory structure:
  logs_dir/
    YYYYMMDD_HHMMSS/
      image.png
      wrist_image.png
      prompt.txt
      state.json
      actions.json (or actions_predicted.json + actions_ground_truth.json)
      result.json
      action_comparison.png (if ground truth exists)

Usage:
  python create_video.py --logs_dir ../logs --output video.mp4 --fps 2
"""
import argparse
import cv2
import os
import json
import numpy as np
from pathlib import Path

def load_json_array(file_path):
    """Load numpy array from JSON file."""
    try:
        with open(file_path, 'r') as f:
            data = json.load(f)
        # Handle different JSON structures
        if isinstance(data, dict):
            # Find the array data in the dict
            for key, value in data.items():
                if isinstance(value, list):
                    return np.array(value)
        elif isinstance(data, list):
            return np.array(data)
        return None
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
        return None

def create_joint_comparison_chart(predicted_actions, gt_actions, width=500, height=400):
    """Create a horizontal bar chart comparing predicted and ground truth actions for each joint with percentage differences."""
    if predicted_actions is None or gt_actions is None:
        # Create empty chart with error message
        chart = np.ones((height, width, 3), dtype=np.uint8) * 255
        cv2.putText(chart, "No action data", (width//2-60, height//2), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)
        return chart
    
    # Create white background
    chart = np.ones((height, width, 3), dtype=np.uint8) * 255
    
    # Chart parameters - å¢å¤§è¾¹è·ä»¥å®¹çº³ç™¾åˆ†æ¯”ä¿¡æ¯
    margin = 50
    chart_width = width - 2 * margin - 80  # é¢„ç•™å³ä¾§ç©ºé—´æ˜¾ç¤ºç™¾åˆ†æ¯”
    chart_height = height - 2 * margin - 40  # é¢„ç•™åº•éƒ¨ç©ºé—´
    
    # Joint parameters
    num_joints = min(len(predicted_actions), len(gt_actions), 7)  # Max 7 joints
    joint_height = chart_height // num_joints
    bar_height = max(joint_height // 2, 20)  # å¢å¤§æ¡å½¢é«˜åº¦ï¼Œæœ€å°20åƒç´ 
    
    # Find max absolute value for scaling
    all_values = np.concatenate([predicted_actions[:num_joints], gt_actions[:num_joints]])
    max_abs_val = max(abs(np.min(all_values)), abs(np.max(all_values)), 0.001)  # Avoid division by zero
    
    # Draw chart
    for i in range(num_joints):
        y_center = margin + i * joint_height + joint_height // 2
        
        # Draw joint label
        cv2.putText(chart, f"J{i}", (5, y_center + 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)
        
        # Draw zero line
        zero_x = margin + chart_width // 2
        cv2.line(chart, (zero_x, y_center - bar_height//2), 
                (zero_x, y_center + bar_height//2), (128, 128, 128), 2)  # åŠ ç²—é›¶çº¿
        
        # Get values for this joint
        pred_val = predicted_actions[i] if i < len(predicted_actions) else 0
        gt_val = gt_actions[i] if i < len(gt_actions) else 0
        
        # Calculate percentage difference
        if abs(gt_val) > 1e-6:  # é¿å…é™¤é›¶
            percentage_diff = abs(pred_val - gt_val) / abs(gt_val) * 100
        else:
            # å¦‚æœground truthæ¥è¿‘é›¶ï¼Œä½¿ç”¨ç»å¯¹å·®å¼‚
            percentage_diff = abs(pred_val - gt_val) * 100
        
        # Draw predicted action bar (blue) - å¢å¤§æ¡å½¢
        if i < len(predicted_actions):
            bar_width = int((abs(pred_val) / max_abs_val) * (chart_width // 2))
            if pred_val >= 0:
                bar_start_x = zero_x
                bar_end_x = zero_x + bar_width
            else:
                bar_start_x = zero_x - bar_width
                bar_end_x = zero_x
            
            cv2.rectangle(chart, 
                         (bar_start_x, y_center - bar_height//2 - 3), 
                         (bar_end_x, y_center - 3), 
                         (255, 0, 0), -1)  # Blue for predicted
            
            # æ·»åŠ é¢„æµ‹å€¼æ ‡ç­¾
            cv2.putText(chart, f"{pred_val:.3f}", (bar_end_x + 5 if pred_val >= 0 else bar_start_x - 60, y_center - 8), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 0, 0), 1)
        
        # Draw ground truth bar (green) - å¢å¤§æ¡å½¢
        if i < len(gt_actions):
            bar_width = int((abs(gt_val) / max_abs_val) * (chart_width // 2))
            if gt_val >= 0:
                bar_start_x = zero_x
                bar_end_x = zero_x + bar_width
            else:
                bar_start_x = zero_x - bar_width
                bar_end_x = zero_x
            
            cv2.rectangle(chart, 
                         (bar_start_x, y_center + 3), 
                         (bar_end_x, y_center + bar_height//2 + 3), 
                         (0, 255, 0), -1)  # Green for ground truth
            
            # æ·»åŠ çœŸå®å€¼æ ‡ç­¾
            cv2.putText(chart, f"{gt_val:.3f}", (bar_end_x + 5 if gt_val >= 0 else bar_start_x - 60, y_center + 18), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 128, 0), 1)
        
        # åœ¨å³ä¾§æ˜¾ç¤ºç™¾åˆ†æ¯”å·®å¼‚
        diff_color = (0, 0, 255) if percentage_diff > 50 else (255, 165, 0) if percentage_diff > 20 else (0, 150, 0)
        cv2.putText(chart, f"{percentage_diff:.1f}%", (width - 70, y_center + 5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, diff_color, 1)
    
    # Add title and legend
    cv2.putText(chart, "Joint Actions Comparison with % Diff", (width//2-120, 25), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
    
    # Add legend - è°ƒæ•´ä½ç½®
    legend_y = height - 35
    cv2.rectangle(chart, (margin, legend_y), (margin + 15, legend_y + 10), (255, 0, 0), -1)
    cv2.putText(chart, "Predicted", (margin + 20, legend_y + 8), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
    
    cv2.rectangle(chart, (margin + 100, legend_y), (margin + 115, legend_y + 10), (0, 255, 0), -1)
    cv2.putText(chart, "Ground Truth", (margin + 120, legend_y + 8), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
    
    # æ·»åŠ ç™¾åˆ†æ¯”è¯´æ˜
    cv2.putText(chart, "% Diff", (width - 70, legend_y + 8), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)
    
    return chart

def format_array_text(arr, label):
    """Format numpy array into readable text lines with individual values."""
    if arr is None:
        return [f"{label}: None"]
    
    arr = np.asarray(arr)
    if arr.ndim == 1:
        # Format 1D array values showing each dimension
        lines = [f"{label}:"]
        for i, val in enumerate(arr):
            lines.append(f"  [{i}]: {val:.6f}")
        return lines
    else:
        return [f"{label}: shape {arr.shape}"]

def format_array_text_grouped(arr, label):
    """Format numpy array into grouped text lines (0-6, 7-13, etc.)."""
    if arr is None:
        return [f"{label}: None"]
    
    arr = np.asarray(arr)
    if arr.ndim == 1:
        lines = [f"{label}:"]  # åªä¿ç•™æ€»æ ‡é¢˜
        print(f"Processing {label} with {len(arr)} elements")  # è°ƒè¯•ä¿¡æ¯
        # Group by 7 elements (0-6, 7-13, etc.)
        for group_start in range(0, len(arr), 7):
            # ç›´æ¥æ˜¾ç¤ºå…ƒç´ ï¼Œä¸æ˜¾ç¤ºç»„æ ‡é¢˜
            for i in range(group_start, min(group_start + 7, len(arr))):
                lines.append(f"  [{i}]: {arr[i]:.6f}")
            
            # Add separator line between groups (except for the last group)
            if group_start + 7 < len(arr):
                lines.append("  " + "-" * 30)
        
        print(f"Generated {len(lines)} lines for {label}")  # è°ƒè¯•ä¿¡æ¯
        return lines
    else:
        return [f"{label}: shape {arr.shape}"]

def create_text_image(text_lines, width, height):
    """Create an image with text on white background."""
    img = np.ones((height, width, 3), dtype=np.uint8) * 255  # White background
    
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.5  # å¢å¤§å­—ä½“
    color = (0, 0, 0)  # Black text
    thickness = 1
    line_height = 22  # å¢åŠ è¡Œé«˜
    
    y = 30  # å¢åŠ èµ·å§‹ä½ç½®
    for line in text_lines:
        # è‡ªåŠ¨æ¢è¡Œå¤„ç†
        words = line.split(' ')
        current_line = ""
        
        for word in words:
            test_line = current_line + (" " if current_line else "") + word
            # æµ‹è¯•æ–‡æœ¬å®½åº¦
            (text_width, _), _ = cv2.getTextSize(test_line, font, font_scale, thickness)
            
            if text_width < width - 30:  # ç•™å‡ºè¾¹è·
                current_line = test_line
            else:
                # å½“å‰è¡Œå·²æ»¡ï¼Œè¾“å‡ºå¹¶å¼€å§‹æ–°è¡Œ
                if current_line and y + line_height < height:
                    cv2.putText(img, current_line, (15, y), font, font_scale, color, thickness, cv2.LINE_AA)
                    y += line_height
                current_line = word
        
        # è¾“å‡ºæœ€åä¸€è¡Œ
        if current_line and y + line_height < height:
            cv2.putText(img, current_line, (15, y), font, font_scale, color, thickness, cv2.LINE_AA)
            y += line_height
    
    return img

def detect_video_mode(logs_dir: Path, runs):
    """
    æ™ºèƒ½æ£€æµ‹è§†é¢‘æ¨¡å¼ï¼š
    - RT-Onlyæ¨¡å¼ï¼šlogsç›®å½•ä¸‹æ²¡æœ‰replayå­æ–‡ä»¶å¤¹
    - Replay-Onlyæ¨¡å¼ï¼šlogsç›®å½•ä¸‹æœ‰replayå­æ–‡ä»¶å¤¹ä½†æ²¡æœ‰rtå­æ–‡ä»¶å¤¹
    - Bothæ¨¡å¼ï¼šlogsç›®å½•ä¸‹æ—¢æœ‰replayå­æ–‡ä»¶å¤¹åˆæœ‰rtå­æ–‡ä»¶å¤¹
    - Simæ¨¡å¼ï¼šlogsç›®å½•åä¸ºsimæˆ–æ£€æµ‹åˆ°ä»¿çœŸæ•°æ®ï¼Œå¥—ç”¨Bothæ¨¡å¼æ˜¾ç¤º
    """
    has_ground_truth = False
    has_rt_images = False
    has_regular_images = False
    
    # æ£€æŸ¥logsç›®å½•ä¸‹çš„å­æ–‡ä»¶å¤¹ç»“æ„æ¥åˆ¤æ–­æ¨¡å¼
    has_replay_folder = (logs_dir / "replay").exists()
    has_rt_folder = (logs_dir / "rt").exists()
    has_sim_folder = (logs_dir / "sim").exists()
    
    # é€šè¿‡ç›®å½•åå¿«é€Ÿåˆ¤æ–­ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼‰
    dir_name = logs_dir.name.lower()
    if (dir_name == "sim" or has_sim_folder) and has_replay_folder:
        # Simæ¨¡å¼ï¼šæ—¢æœ‰replayåˆæœ‰simæ–‡ä»¶å¤¹ï¼Œå¥—ç”¨Bothæ¨¡å¼çš„æ˜¾ç¤ºé€»è¾‘
        return {
            "mode_name": "Sim Mode (Simulation vs Dataset, using Both display)",
            "is_replay_mode": True,  # å¥—ç”¨Bothæ¨¡å¼ï¼Œæ‰€ä»¥è®¾ä¸ºTrue
            "has_rt_images": True   # å¥—ç”¨Bothæ¨¡å¼ï¼Œæ˜¾ç¤ºsimæ•°æ®ä½œä¸º"RT"å¯¹æ¯”
        }
    elif (dir_name == "sim" or has_sim_folder) and not has_replay_folder:
        # çº¯Simæ¨¡å¼ï¼šåªæœ‰simæ–‡ä»¶å¤¹
        return {
            "mode_name": "Pure Sim Mode (Simulation Only)",
            "is_replay_mode": False,
            "has_rt_images": False
        }
    elif not has_replay_folder and has_rt_folder:
        # åªæœ‰rtæ–‡ä»¶å¤¹ï¼Œæ²¡æœ‰replayæ–‡ä»¶å¤¹ -> RT-Onlyæ¨¡å¼
        return {
            "mode_name": "RT-Only Mode (Real-time Only)",
            "is_replay_mode": False,
            "has_rt_images": True
        }
    elif has_replay_folder and not has_rt_folder and not has_sim_folder:
        # åªæœ‰replayæ–‡ä»¶å¤¹ï¼Œæ²¡æœ‰rtæ–‡ä»¶å¤¹ -> Replay-Onlyæ¨¡å¼
        return {
            "mode_name": "Replay-Only Mode (Dataset Comparison)",
            "is_replay_mode": True,
            "has_rt_images": False
        }
    elif has_replay_folder and has_rt_folder:
        # æ—¢æœ‰replayåˆæœ‰rtæ–‡ä»¶å¤¹ -> Bothæ¨¡å¼
        return {
            "mode_name": "Both Mode (Dataset + Real-time Comparison)",
            "is_replay_mode": True,
            "has_rt_images": True
        }
    
    # é€šè¿‡ç›®å½•åå¿«é€Ÿåˆ¤æ–­ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºåå¤‡ï¼‰
    dir_name = logs_dir.name.lower()
    if dir_name == "rt":
        return {
            "mode_name": "RT-Only Mode (Real-time Images Only)",
            "is_replay_mode": False,
            "has_rt_images": True
        }
    elif dir_name == "replay":
        return {
            "mode_name": "Replay-Only Mode (Dataset Comparison)",
            "is_replay_mode": True,
            "has_rt_images": False
        }
    elif dir_name == "both":
        return {
            "mode_name": "Both Mode (Dataset + Real-time Comparison)",
            "is_replay_mode": True,
            "has_rt_images": True
        }
    
    # å¦‚æœç›®å½•åä¸æ˜ç¡®ï¼Œåˆ™åˆ†ææ–‡ä»¶å†…å®¹
    for run in runs[:5]:  # åªæ£€æŸ¥å‰5ä¸ªè¿è¡Œä»¥æé«˜æ•ˆç‡
        # æ£€æŸ¥æ˜¯å¦æœ‰ground truthå¯¹æ¯”æ–‡ä»¶
        if (run / "actions_predicted.json").exists() and (run / "actions_ground_truth.json").exists():
            has_ground_truth = True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®æ—¶å›¾åƒ
        if (run / "rt_image.png").exists() or (run / "rt_wrist_image.png").exists():
            has_rt_images = True
            
        # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸è§„å›¾åƒ
        if (run / "image.png").exists():
            has_regular_images = True
    
    # æ ¹æ®æ–‡ä»¶å­˜åœ¨æƒ…å†µåˆ¤æ–­æ¨¡å¼
    if has_ground_truth and has_rt_images:
        mode_name = "Both Mode (Dataset + Real-time Comparison)"
        is_replay_mode = True
    elif has_ground_truth and not has_rt_images:
        mode_name = "Replay-Only Mode (Dataset Comparison)"
        is_replay_mode = True
    elif not has_ground_truth and has_rt_images:
        mode_name = "RT-Only Mode (Real-time Images Only)"
        is_replay_mode = False
    elif not has_ground_truth and not has_rt_images and has_regular_images:
        mode_name = "Real-time Test Mode"
        is_replay_mode = False
    else:
        mode_name = "Unknown Mode"
        is_replay_mode = False
    
    return {
        "mode_name": mode_name,
        "is_replay_mode": is_replay_mode,
        "has_rt_images": has_rt_images
    }

def resize_image(img, target_height, max_width=None):
    """Resize image maintaining aspect ratio with optional max width limit."""
    h, w = img.shape[:2]
    aspect_ratio = w / h
    new_width = int(target_height * aspect_ratio)
    
    # If max_width is specified and new_width exceeds it, scale down
    if max_width and new_width > max_width:
        new_width = max_width
        target_height = int(max_width / aspect_ratio)
    
    return cv2.resize(img, (new_width, target_height))

def main(logs_dir: Path, output: Path, fps: int):
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦é‡å®šå‘åˆ°å­ç›®å½•
    has_replay_folder = (logs_dir / "replay").exists()
    has_rt_folder = (logs_dir / "rt").exists()
    has_sim_folder = (logs_dir / "sim").exists()
    
    # æ™ºèƒ½é‡å®šå‘ï¼šæ ¹æ®å­æ–‡ä»¶å¤¹ç»“æ„
    if has_sim_folder and has_replay_folder and not has_rt_folder:
        print(f"ğŸ”„ é‡å®šå‘åˆ°Simæ¨¡å¼ç›®å½•ï¼Œå¥—ç”¨Bothæ¨¡å¼å±•ç¤º: {logs_dir / 'replay'} + {logs_dir / 'sim'}")
        # Simæ¨¡å¼ï¼šå¥—ç”¨Bothæ¨¡å¼çš„å±•ç¤ºé€»è¾‘ï¼Œå°†simæ–‡ä»¶å¤¹ä½œä¸ºRTæ•°æ®æº
        actual_logs_dir = logs_dir / "replay"  # ä¸»è¦ä½¿ç”¨replayæ•°æ®
        rt_logs_dir = logs_dir / "sim"  # simæ•°æ®ç”¨äºå¯¹æ¯”ï¼ˆç›¸å½“äºRTæ•°æ®ï¼‰
    elif has_sim_folder and not has_replay_folder and not has_rt_folder:
        print(f"ğŸ”„ é‡å®šå‘åˆ°Pure Simæ¨¡å¼ç›®å½•: {logs_dir / 'sim'}")
        # çº¯Simæ¨¡å¼ï¼šåªæœ‰simæ–‡ä»¶å¤¹çš„æƒ…å†µ
        actual_logs_dir = logs_dir / "sim"
        rt_logs_dir = None
    elif not has_replay_folder and has_rt_folder and not has_sim_folder:
        print(f"ğŸ”„ é‡å®šå‘åˆ°RTæ¨¡å¼ç›®å½•: {logs_dir / 'rt'}")
        actual_logs_dir = logs_dir / "rt"
        rt_logs_dir = None  # RT-Onlyæ¨¡å¼ä¸éœ€è¦å¯¹æ¯”æ•°æ®
    elif has_replay_folder and not has_rt_folder and not has_sim_folder:
        print(f"ğŸ”„ é‡å®šå‘åˆ°Replayæ¨¡å¼ç›®å½•: {logs_dir / 'replay'}")
        actual_logs_dir = logs_dir / "replay"
        rt_logs_dir = None  # Replay-Onlyæ¨¡å¼ä¸éœ€è¦RTæ•°æ®
    elif has_replay_folder and has_rt_folder:
        print(f"ğŸ”„ æ£€æµ‹åˆ°Bothæ¨¡å¼ï¼Œåˆå¹¶replayå’Œrtæ•°æ®")
        # Bothæ¨¡å¼ï¼šéœ€è¦åˆå¹¶ä¸¤ä¸ªç›®å½•çš„æ•°æ®
        actual_logs_dir = logs_dir / "replay"  # ä¸»è¦ä½¿ç”¨replayæ•°æ®
        rt_logs_dir = logs_dir / "rt"  # RTæ•°æ®ç”¨äºå¯¹æ¯”
    else:
        actual_logs_dir = logs_dir
        rt_logs_dir = None  # é»˜è®¤æƒ…å†µä¸‹ä¸éœ€è¦RTå¯¹æ¯”æ•°æ®
    
    # Collect and sort run directories
    runs = [d for d in actual_logs_dir.iterdir() if d.is_dir()]
    if not runs:
        print(f"No run subdirectories found in {actual_logs_dir}")
        return
    
    # In both mode, we need to merge RT comparison data
    if rt_logs_dir and rt_logs_dir.exists():
        rt_runs = {d.name: d for d in rt_logs_dir.iterdir() if d.is_dir()}
        print(f"ğŸ“Š æ‰¾åˆ° {len(rt_runs)} ä¸ªRTå¯¹æ¯”æ•°æ®ç›®å½•")
    else:
        rt_runs = {}

    # Sort runs by timestamp, handling both old and new formats
    def get_timestamp_sort_key(run_dir):
        name = run_dir.name
        try:
            # Handle new format: YYYYMMDD_HHMMSS_mmm
            if name.count('_') == 2:
                date_part, time_part, ms_part = name.split('_')
                return f"{date_part}_{time_part}_{ms_part.zfill(3)}"
            # Handle old format: YYYYMMDD_HHMMSS
            elif name.count('_') == 1:
                return f"{name}_000"  # Add 000 milliseconds for old format
            else:
                return name
        except:
            return name
    
    runs.sort(key=get_timestamp_sort_key)
    
    # æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼šæ ¹æ®ç›®å½•ç»“æ„å’Œæ–‡ä»¶å†…å®¹ï¼ˆä½¿ç”¨åŸå§‹logs_dirè¿›è¡Œæ£€æµ‹ï¼‰
    mode_info = detect_video_mode(logs_dir, runs)
    is_replay_mode = mode_info["is_replay_mode"]
    mode_name = mode_info["mode_name"]
    has_rt_images_global = mode_info["has_rt_images"]
    
    print(f"ğŸ¯ æ£€æµ‹åˆ°æ¨¡å¼: {mode_name}")
    if has_rt_images_global:
        print("ğŸ“· åŒ…å«å®æ—¶å›¾åƒæ•°æ®")
    
    # Define layout parameters for 1080p video
    video_width = 1920   # 1080på®½åº¦
    video_height = 1080  # 1080pé«˜åº¦
    
    img_height = 300     # ä¿æŒå›¾åƒåˆé€‚å¤§å°
    spacing = 40         # å¢å¤§é—´è·
    
    # å®šä¹‰åŒºåŸŸåˆ†å¸ƒ - ä¼˜åŒ–æ–‡å­—åŒºåŸŸ
    # å·¦ä¾§ï¼šå›¾åƒåŒºåŸŸ (ä¸»å›¾åƒ + æ‰‹è…•å›¾åƒ + æ¯”è¾ƒå›¾è¡¨)
    # å³ä¾§ï¼šæ–‡å­—åŒºåŸŸåˆ†ä¸ºå¤šåˆ—
    left_area_width = 950     # å‡å°å·¦ä¾§å›¾åƒåŒºåŸŸå®½åº¦ï¼Œä¸ºæ–‡å­—åŒºåŸŸè®©å‡ºæ›´å¤šç©ºé—´
    right_area_width = 930    # å¢åŠ å³ä¾§æ–‡å­—åŒºåŸŸå®½åº¦
    
    text_column_width = 300   # å‡å°æ¯åˆ—æ–‡å­—å®½åº¦ï¼Œå¯ä»¥æ”¾æ›´å¤šåˆ—
    
    if is_replay_mode:
        print(f"Creating video in REPLAY MODE ({mode_name}) - 1080p")
    else:
        print(f"Creating video in REAL-TIME MODE ({mode_name}) - 1080p")
    
    # Setup video writer - ä½¿ç”¨æ›´é€šç”¨çš„H.264ç¼–ç å™¨
    # å°è¯•å¤šç§ç¼–ç å™¨ï¼Œä¼˜å…ˆä½¿ç”¨æœ€å…¼å®¹çš„
    fourcc_options = [
        cv2.VideoWriter_fourcc(*'H264'),  # H.264 (æœ€é€šç”¨)
        cv2.VideoWriter_fourcc(*'XVID'),  # XVID (å¹¿æ³›æ”¯æŒ)
        cv2.VideoWriter_fourcc(*'MJPG'),  # Motion JPEG (å…¼å®¹æ€§å¥½)
        cv2.VideoWriter_fourcc(*'mp4v')   # MP4V (åŸå§‹é€‰é¡¹ä½œä¸ºåå¤‡)
    ]
    
    video = None
    for fourcc in fourcc_options:
        try:
            video = cv2.VideoWriter(str(output), fourcc, fps, (video_width, video_height))
            if video.isOpened():
                print(f"âœ… ä½¿ç”¨ç¼–ç å™¨: {fourcc}")
                break
            else:
                video.release()
                video = None
        except:
            if video:
                video.release()
                video = None
                
    if video is None:
        print("âŒ æ— æ³•åˆå§‹åŒ–è§†é¢‘ç¼–ç å™¨ï¼Œä½¿ç”¨é»˜è®¤é€‰é¡¹")
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        video = cv2.VideoWriter(str(output), fourcc, fps, (video_width, video_height))

    for frame_idx, run in enumerate(runs, 1):  # ä»1å¼€å§‹è®¡æ•°å¸§æ•°
        img_path = run / "image.png"
        wrist_img_path = run / "wrist_image.png"
        prompt_path = run / "prompt.txt"
        state_path = run / "state.json"
        actions_path = run / "actions.json"
        
        # RTå›¾åƒè·¯å¾„ - åˆå§‹è®¾ä¸ºNone
        rt_img_path = None
        rt_wrist_img_path = None
        
        # In both mode, find corresponding RT data by index (æŒ‰é¡ºåºé…å¯¹)
        if rt_runs:
            # å°†rt_runsè½¬æ¢ä¸ºæŒ‰åç§°æ’åºçš„åˆ—è¡¨
            sorted_rt_runs = sorted(rt_runs.items())
            # æŒ‰å½“å‰runçš„ç´¢å¼•æ‰¾å¯¹åº”çš„RTæ•°æ®
            current_run_index = runs.index(run)
            if current_run_index < len(sorted_rt_runs):
                rt_run_name, rt_run = sorted_rt_runs[current_run_index]
                # RTæ•°æ®ç°åœ¨ä¹Ÿä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶åï¼šimage.pngå’Œwrist_image.png
                potential_rt_img = rt_run / "image.png"
                potential_rt_wrist_img = rt_run / "wrist_image.png"
                
                if potential_rt_img.exists():
                    rt_img_path = potential_rt_img
                if potential_rt_wrist_img.exists():
                    rt_wrist_img_path = potential_rt_wrist_img
                
        actions_pred_path = run / "actions_predicted.json"
        actions_gt_path = run / "actions_ground_truth.json"
        comparison_plot_path = run / "action_comparison.png"
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶ - æ ¹æ®æ¨¡å¼è°ƒæ•´
        if mode_name.startswith("RT-Only"):
            # RT-Onlyæ¨¡å¼ï¼šç°åœ¨RTæ•°æ®ä¿å­˜ä¸ºimage.pngå’Œwrist_image.pngï¼ˆé”®åç»Ÿä¸€åï¼‰
            if not img_path.exists() or not prompt_path.exists():
                print(f"Skipping {run}, missing required RT files (image.png or prompt.txt)")
                continue
            # RT-Onlyæ¨¡å¼ä¸‹ä¸éœ€è¦é¢å¤–çš„RTå¯¹æ¯”å›¾åƒ
            rt_img_path = None
            rt_wrist_img_path = None
        else:
            # å…¶ä»–æ¨¡å¼ï¼šéœ€è¦image.pngå’Œprompt.txt
            if not img_path.exists() or not prompt_path.exists():
                print(f"Skipping {run}, missing required files (image.png or prompt.txt)")
                continue
            
        # Create white background frame (1080p)
        frame = np.ones((video_height, video_width, 3), dtype=np.uint8) * 255
        
        # å·¦ä¾§å›¾åƒåŒºåŸŸå¸ƒå±€ - é‡æ–°è®¾è®¡ä¸ºä¸Šä¸‹å¸ƒå±€
        # ä¸ŠåŠéƒ¨åˆ†ï¼šä¸»ç›¸æœºå’Œæ‰‹è…•å›¾ç‰‡å¹¶åˆ—
        # ä¸­é—´éƒ¨åˆ†ï¼šå®æ—¶å›¾åƒå¹¶åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        # ä¸‹åŠéƒ¨åˆ†ï¼šå¯¹æ¯”å›¾è¡¨
        
        images_start_x = spacing
        images_start_y = spacing
        
        # è®¡ç®—å›¾åƒåŒºåŸŸå°ºå¯¸
        available_img_width = left_area_width - spacing * 2
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®æ—¶å›¾åƒ
        has_rt_images = rt_img_path is not None or rt_wrist_img_path is not None
        
        # æ ¹æ®æ˜¯å¦æœ‰å®æ—¶å›¾åƒè°ƒæ•´å¸ƒå±€
        if has_rt_images:
            # ä¸‰å±‚å¸ƒå±€ï¼šRTå›¾åƒåœ¨ä¸Šã€Replayå›¾åƒåœ¨ä¸­ã€å¯¹æ¯”å›¾è¡¨åœ¨ä¸‹
            img_area_height = (video_height - spacing * 4) // 3  # åˆ†ä¸ºä¸‰éƒ¨åˆ†
        else:
            # ä¸¤å±‚å¸ƒå±€ï¼šReplayå›¾åƒã€å¯¹æ¯”å›¾è¡¨
            img_area_height = (video_height - spacing * 3) // 2  # åˆ†ä¸ºä¸Šä¸‹ä¸¤éƒ¨åˆ†
        
        # ç¬¬ä¸€å±‚ï¼šRTå›¾åƒï¼ˆå¦‚æœå­˜åœ¨ï¼‰- æ”¾åœ¨æœ€ä¸Šé¢
        if has_rt_images:
            rt_images_y = images_start_y
            current_x_offset = images_start_x
            
            # Load and resize realtime main image
            if rt_img_path is not None:
                rt_main_img = cv2.imread(str(rt_img_path))
                if rt_main_img is not None:
                    max_img_width = available_img_width // 2 - spacing
                    rt_main_img = resize_image(rt_main_img, img_height, max_width=max_img_width)
                    h, w = rt_main_img.shape[:2]
                    frame[rt_images_y:rt_images_y+h, current_x_offset:current_x_offset+w] = rt_main_img
                    
                    # æ·»åŠ RT/Simæ ‡ç­¾
                    if mode_name.startswith("Sim"):
                        cv2.putText(frame, "Sim Main", (current_x_offset, rt_images_y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 165, 0), 2)  # æ©™è‰²ä»£è¡¨Sim
                    else:
                        cv2.putText(frame, "RT Main", (current_x_offset, rt_images_y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    current_x_offset += w + spacing
            
            # Load and resize realtime wrist image
            if rt_wrist_img_path is not None:
                rt_wrist_img = cv2.imread(str(rt_wrist_img_path))
                if rt_wrist_img is not None:
                    max_img_width = available_img_width // 2 - spacing
                    rt_wrist_img = resize_image(rt_wrist_img, img_height, max_width=max_img_width)
                    h, w = rt_wrist_img.shape[:2]
                    frame[rt_images_y:rt_images_y+h, current_x_offset:current_x_offset+w] = rt_wrist_img
                    
                    # æ·»åŠ RT/Simæ ‡ç­¾
                    if mode_name.startswith("Sim"):
                        cv2.putText(frame, "Sim Wrist", (current_x_offset, rt_images_y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 165, 0), 2)  # æ©™è‰²ä»£è¡¨Sim
                    else:
                        cv2.putText(frame, "RT Wrist", (current_x_offset, rt_images_y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # ç¬¬äºŒå±‚ï¼šä¸»å›¾åƒï¼ˆä¸»ç›¸æœºå’Œæ‰‹è…•å›¾ç‰‡å¹¶åˆ—ï¼‰
        if has_rt_images:
            replay_images_y = images_start_y + img_height + spacing
        else:
            replay_images_y = images_start_y
            
        current_x_offset = images_start_x
        
        # Load and resize main image
        main_img = cv2.imread(str(img_path))
        if main_img is not None:
            # ä¸ºå¹¶åˆ—æ˜¾ç¤ºè°ƒæ•´å›¾åƒå¤§å°
            max_img_width = available_img_width // 2 - spacing
            main_img = resize_image(main_img, img_height, max_width=max_img_width)
            h, w = main_img.shape[:2]
            frame[replay_images_y:replay_images_y+h, current_x_offset:current_x_offset+w] = main_img
            
            # æ ¹æ®æ¨¡å¼æ·»åŠ åˆé€‚çš„æ ‡ç­¾
            if mode_name.startswith("RT-Only"):
                cv2.putText(frame, "RT Main", (current_x_offset, replay_images_y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            elif is_replay_mode:
                cv2.putText(frame, "Replay Main", (current_x_offset, replay_images_y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            current_x_offset += w + spacing
        
        # Load and resize wrist image (å³ä¾§å¹¶åˆ—)
        if wrist_img_path.exists():
            wrist_img = cv2.imread(str(wrist_img_path))
            if wrist_img is not None:
                max_img_width = available_img_width // 2 - spacing
                wrist_img = resize_image(wrist_img, img_height, max_width=max_img_width)
                h, w = wrist_img.shape[:2]
                frame[replay_images_y:replay_images_y+h, current_x_offset:current_x_offset+w] = wrist_img
                
                # æ ¹æ®æ¨¡å¼æ·»åŠ åˆé€‚çš„æ ‡ç­¾
                if mode_name.startswith("RT-Only"):
                    cv2.putText(frame, "RT Wrist", (current_x_offset, replay_images_y-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                elif is_replay_mode:
                    cv2.putText(frame, "Replay Wrist", (current_x_offset, replay_images_y-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æœ€åä¸€å±‚ï¼šå¯¹æ¯”å›¾è¡¨
        if is_replay_mode and comparison_plot_path.exists():
            comparison_img = cv2.imread(str(comparison_plot_path))
            if comparison_img is not None:
                # å¯¹æ¯”å›¾è¡¨æ”¾åœ¨æœ€ä¸‹é¢
                if has_rt_images:
                    # RTå›¾åƒ + Replayå›¾åƒ + å¯¹æ¯”å›¾è¡¨
                    bottom_y = images_start_y + (img_height + spacing) * 2
                else:
                    # Replayå›¾åƒ + å¯¹æ¯”å›¾è¡¨
                    bottom_y = replay_images_y + img_height + spacing
                    
                max_comparison_width = available_img_width  # ä½¿ç”¨å®Œæ•´å®½åº¦
                max_comparison_height = img_area_height + 100  # å¢åŠ é«˜åº¦
                
                # é¦–å…ˆæŒ‰é«˜åº¦ç¼©æ”¾ï¼Œä¿æŒå®½é«˜æ¯”
                comparison_img = resize_image(comparison_img, max_comparison_height, max_width=max_comparison_width)
                h, w = comparison_img.shape[:2]
                
                # å±…ä¸­æ”¾ç½®å¯¹æ¯”å›¾è¡¨
                center_x = images_start_x + (available_img_width - w) // 2
                
                # ç¡®ä¿å›¾è¡¨ä¸ä¼šè¶…å‡ºè§†é¢‘è¾¹ç•Œ
                if bottom_y + h > video_height:
                    h = video_height - bottom_y - spacing
                    comparison_img = comparison_img[:h, :, :]
                if center_x + w > video_width:
                    w = video_width - center_x - spacing
                    comparison_img = comparison_img[:, :w, :]
                    
                if h > 0 and w > 0:  # ç¡®ä¿æœ‰æ•ˆå°ºå¯¸
                    frame[bottom_y:bottom_y+h, center_x:center_x+w] = comparison_img
        
        # å‡†å¤‡æ–‡å­—å†…å®¹ - åˆ†ä¸ºä¸¤åˆ—
        # å·¦åˆ—ï¼šåŸºæœ¬ä¿¡æ¯å’ŒçŠ¶æ€
        left_text_lines = []
        # å³åˆ—ï¼šåŠ¨ä½œæ•°æ®
        right_text_lines = []
        
        # Determine mode based on available files
        has_comparison = actions_pred_path.exists() and actions_gt_path.exists()
        display_mode = mode_name  # ä½¿ç”¨æ™ºèƒ½æ£€æµ‹çš„æ¨¡å¼åç§°
        
        # Add frame number, mode and timestamp to left column
        left_text_lines.extend([
            f"# Frame {frame_idx}",
            ""
        ])
        
        timestamp_str = run.name  # YYYYMMDD_HHMMSS_mmm format (with milliseconds)
        try:
            # Handle both old format (YYYYMMDD_HHMMSS) and new format (YYYYMMDD_HHMMSS_mmm)
            if '_' in timestamp_str and len(timestamp_str.split('_')) >= 2:
                parts = timestamp_str.split('_')
                date_part = parts[0]  # YYYYMMDD
                time_part = parts[1]  # HHMMSS
                ms_part = parts[2] if len(parts) > 2 else None  # mmm (milliseconds)
                
                formatted_date = f"{date_part[:4]}-{date_part[4:6]}-{date_part[6:8]}"
                formatted_time = f"{time_part[:2]}:{time_part[2:4]}:{time_part[4:6]}"
                
                if ms_part:
                    formatted_time += f".{ms_part}"
                
                left_text_lines.extend([
                    f"Mode: {display_mode}",
                    f"Time: {formatted_date}",
                    f"      {formatted_time}",
                    ""
                ])
            else:
                # Fallback for old format
                left_text_lines.extend([
                    f"Mode: {display_mode}",
                    f"Time: {timestamp_str}",
                    ""
                ])
        except:
            left_text_lines.extend([
                f"Mode: {display_mode}",
                f"Time: {timestamp_str}",
                ""
            ])
        
        # Add prompt to left column
        if prompt_path.exists():
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt = f.read().strip()
            left_text_lines.extend([
                "Task Prompt:",
                prompt,  # ä¸å†å¼ºåˆ¶æˆªæ–­ï¼Œè®©è‡ªåŠ¨æ¢è¡Œå¤„ç†
                ""
            ])
        
        # Add state information to left column - Bothæ¨¡å¼å’ŒSimæ¨¡å¼ä¸‹æ˜¾ç¤ºä¸¤ä¸ªrobot state
        if state_path.exists():
            state = load_json_array(state_path)
            if (mode_name.startswith("Both") or mode_name.startswith("Sim")) and rt_runs:
                # Bothæ¨¡å¼å’ŒSimæ¨¡å¼ï¼šå…ˆæ˜¾ç¤ºRT/Sim robot state (åœ¨ä¸Š)ï¼Œå†æ˜¾ç¤ºReplay robot state (åœ¨ä¸‹)
                
                # 1. è·å–å¯¹åº”çš„RT/Sim robot state
                current_run_index = runs.index(run)
                sorted_rt_runs = sorted(rt_runs.items())
                if current_run_index < len(sorted_rt_runs):
                    rt_run_name, rt_run = sorted_rt_runs[current_run_index]
                    rt_state_path = rt_run / "state.json"
                    if rt_state_path.exists():
                        rt_state = load_json_array(rt_state_path)
                        if mode_name.startswith("Sim"):
                            left_text_lines.extend(format_array_text(rt_state, "Robot State (Sim)"))
                        else:
                            left_text_lines.extend(format_array_text(rt_state, "Robot State (RT)"))
                        left_text_lines.append("")
                    else:
                        if mode_name.startswith("Sim"):
                            left_text_lines.extend([
                                "Robot State (Sim): Not available",
                                ""
                            ])
                        else:
                            left_text_lines.extend([
                                "Robot State (RT): Not available",
                                ""
                            ])
                
                # 2. æ˜¾ç¤ºReplay robot state
                left_text_lines.extend(format_array_text(state, "Robot State (Replay)"))
                left_text_lines.append("")
                
            else:
                # å…¶ä»–æ¨¡å¼ï¼šæ˜¾ç¤ºå•ä¸ªrobot state
                state_label = "Robot State"
                if mode_name.startswith("RT-Only"):
                    state_label = "Robot State (RT)"
                elif mode_name.startswith("Sim"):
                    state_label = "Robot State (Simulation)"
                left_text_lines.extend(format_array_text(state, state_label))
                left_text_lines.append("")
        else:
            left_text_lines.extend([
                "Robot State: Not available",
                ""
            ])
        
        # Add realtime image status to left column
        if has_rt_images:  # ä½¿ç”¨å½“å‰runçš„RTå›¾åƒæ£€æŸ¥ç»“æœè€Œä¸æ˜¯å…¨å±€å˜é‡
            left_text_lines.extend([
                "Realtime Images:",
                f"Main: {'True' if rt_img_path and rt_img_path.exists() else 'False'}",
                f"Wrist: {'True' if rt_wrist_img_path and rt_wrist_img_path.exists() else 'False'}",
                ""
            ])
        
        # Add actions information to right column
        predicted_actions = None
        gt_actions = None
        
        if has_comparison:
            right_text_lines.extend([
                "=== REPLAY MODE ===",
                "Model vs Dataset:",
                ""
            ])
            
            # Load predicted actions
            predicted_actions = load_json_array(actions_pred_path)
            if predicted_actions is not None and len(predicted_actions) == 70:
                predicted_actions = predicted_actions[:7]  # åªå–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥çš„7ä¸ªåŠ¨ä½œ
            if predicted_actions is not None:
                right_text_lines.extend(format_array_text_grouped(predicted_actions, "Model Predictions"))
                right_text_lines.append("")
            
            # Load ground truth actions
            gt_actions = load_json_array(actions_gt_path)
            if gt_actions is not None:
                right_text_lines.extend(format_array_text_grouped(gt_actions, "Ground Truth"))
                right_text_lines.append("")
            
            # Add differences
            if predicted_actions is not None and gt_actions is not None:
                diff = predicted_actions - gt_actions
                right_text_lines.extend(format_array_text_grouped(diff, "Difference"))
                right_text_lines.append("")
            
            # Add comparison metrics
            metrics_path = run / "comparison_metrics.json"
            if metrics_path.exists():
                try:
                    with open(metrics_path, 'r') as f:
                        metrics = json.load(f)
                    right_text_lines.extend([
                        "Performance Metrics:",
                        f"MSE: {metrics.get('mse', 'N/A'):.8f}",
                        f"MAE: {metrics.get('mae', 'N/A'):.8f}",
                        f"RMSE: {metrics.get('rmse', 'N/A'):.8f}",
                        f"Corr: {metrics.get('correlation', 'N/A'):.6f}",
                        f"MaxDiff: {metrics.get('max_difference', 'N/A'):.8f}",
                        ""
                    ])
                except Exception as e:
                    right_text_lines.extend([f"Metrics Error: {e}", ""])
        
        elif actions_path.exists():
            right_text_lines.extend([
                "=== REAL-TIME TEST ===",
                "Live Predictions:",
                ""
            ])
            # Load single actions file
            actions = load_json_array(actions_path)
            if actions is not None:
                right_text_lines.extend(format_array_text_grouped(actions, "Model Output"))
        else:
            right_text_lines.extend([
                "=== NO ACTIONS ===",
                "No action data found",
                ""
            ])
        
        # åˆ›å»ºå¹¶æ”¾ç½®æ–‡å­—å›¾åƒ - æ™ºèƒ½åˆ†åˆ—å¤„ç†ï¼Œå‘å·¦ç§»åŠ¨æ–‡å­—åŒºåŸŸ
        right_area_x_start = left_area_width - spacing  # å‘å·¦ç§»åŠ¨ï¼Œå‡å°‘é—´è·
        
        # å·¦åˆ—æ–‡å­— (åŸºæœ¬ä¿¡æ¯)
        left_text_img = create_text_image(left_text_lines, text_column_width, video_height - spacing * 2)
        text_y_start = spacing
        frame[text_y_start:text_y_start + left_text_img.shape[0], 
              right_area_x_start:right_area_x_start + text_column_width] = left_text_img
        
        # åœ¨bothæ¨¡å¼ä¸‹ï¼Œä¸ºå…³èŠ‚å¯¹æ¯”å›¾é¢„ç•™ç©ºé—´
        chart_height = 400  # å¢å¤§å›¾è¡¨é«˜åº¦
        chart_width = 500   # å¢å¤§å›¾è¡¨å®½åº¦
        chart_reserved_space = chart_height + spacing if has_comparison else 0
        
        # æ™ºèƒ½åˆ†å‰²å³ä¾§æ–‡å­—å†…å®¹ - æ ¹æ®å®é™…å¯æ˜¾ç¤ºè¡Œæ•°è®¡ç®—ï¼ˆå‡å»å›¾è¡¨ç©ºé—´ï¼‰
        line_height = 22
        available_height = video_height - spacing * 2 - 30 - chart_reserved_space  # å‡å»å›¾è¡¨ç©ºé—´
        max_lines_per_column = int(available_height // line_height) - 2  # ç•™å‡ºä¸€äº›ç¼“å†²
        
        print(f"Available height: {available_height}, Max lines per column: {max_lines_per_column}")
        print(f"Total right text lines: {len(right_text_lines)}")
        
        # è®¡ç®—éœ€è¦å¤šå°‘åˆ—
        num_columns_needed = (len(right_text_lines) + max_lines_per_column - 1) // max_lines_per_column if right_text_lines else 0
        print(f"Need {num_columns_needed} columns for right text")
        
        # åˆ†å‰²æ–‡å­—åˆ°å¤šåˆ—
        text_columns = []
        for i in range(num_columns_needed):
            start_idx = i * max_lines_per_column
            end_idx = min((i + 1) * max_lines_per_column, len(right_text_lines))
            text_columns.append(right_text_lines[start_idx:end_idx])
            print(f"Column {i+1}: lines {start_idx} to {end_idx-1} ({len(text_columns[i])} lines)")
        
        # æ¸²æŸ“å„åˆ— - æ›´ç´§å‡‘çš„å¸ƒå±€
        current_x = right_area_x_start + text_column_width + spacing // 4  # å‡å°‘åˆ—é—´è·
        available_width_for_columns = video_width - current_x - spacing // 2  # å‡å°‘å³è¾¹è·
        
        for i, column_text in enumerate(text_columns):
            if not column_text:
                continue
                
            # è®¡ç®—åˆ—å®½ - æ›´å‡åŒ€çš„åˆ†é…
            if i == len(text_columns) - 1:  # æœ€åä¸€åˆ—ä½¿ç”¨å‰©ä½™ç©ºé—´
                column_width = min(text_column_width, video_width - current_x - spacing // 2)
            else:
                column_width = text_column_width
            
            if column_width > 100:  # ç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´æ˜¾ç¤ºæ–‡å­—
                text_img = create_text_image(column_text, column_width, video_height - spacing * 2)
                end_x = min(current_x + column_width, video_width - spacing // 2)
                
                if current_x < video_width - spacing // 2:
                    frame[text_y_start:text_y_start + text_img.shape[0], 
                          current_x:end_x] = text_img[:, :end_x-current_x]
                    print(f"Rendered column {i+1} at x={current_x}, width={end_x-current_x}")
                    
                current_x += column_width + spacing // 4  # ç§»åŠ¨åˆ°ä¸‹ä¸€åˆ—
        
        # åœ¨bothæ¨¡å¼ä¸‹æ·»åŠ å…³èŠ‚å¯¹æ¯”å›¾
        if has_comparison and predicted_actions is not None and gt_actions is not None:
            # åˆ›å»ºå…³èŠ‚å¯¹æ¯”å›¾
            joint_chart = create_joint_comparison_chart(predicted_actions, gt_actions, chart_width, chart_height)
            
            # å°†å›¾è¡¨æ”¾ç½®åœ¨å³ä¾§åŒºåŸŸåº•éƒ¨
            chart_x = right_area_x_start + text_column_width + spacing
            chart_y = video_height - chart_height - spacing
            
            # ç¡®ä¿å›¾è¡¨ä¸è¶…å‡ºè¾¹ç•Œ
            end_x = min(chart_x + chart_width, video_width - spacing)
            end_y = min(chart_y + chart_height, video_height - spacing)
            actual_width = end_x - chart_x
            actual_height = end_y - chart_y
            
            if actual_width > 0 and actual_height > 0:
                frame[chart_y:end_y, chart_x:end_x] = joint_chart[:actual_height, :actual_width]
            else:
                print(f"Skipping column {i+1} - insufficient width ({column_width})")
                break
        
        video.write(frame)

    video.release()
    print(f"Video saved to {output}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Create video from logs')
    parser.add_argument('--logs_dir', type=str, default='../logs', help='Parent logs directory')
    parser.add_argument('--output', type=str, default='../logs/output.mp4', help='Output video file path')
    parser.add_argument('--fps', type=int, default=2, help='Frames per second')
    args = parser.parse_args()
    main(Path(args.logs_dir), Path(args.output), args.fps)
